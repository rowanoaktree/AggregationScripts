{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import patches, text, patheffects\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_DBSCAN(df):\n",
    "    x = df[[\"c_x\", \"c_y\"]].to_numpy()\n",
    "    cluster = DBSCAN(eps=15, min_samples=5).fit(x)\n",
    "    labels = cluster.labels_\n",
    "    df[\"cluster_id\"] = labels\n",
    "    return labels\n",
    "    #n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    #n_noise_ = list(labels).count(-1)\n",
    "    \n",
    "    #EVENTUALLY: run DBSCAN, or sort for running H-Cluster if DBSCAN gives a bad result\n",
    "    #hcluster = []\n",
    "    #comp = int(len(df)) / len(((df[\"labeler_id\"].unique())))\n",
    "    #decision = comp / int(n_clusters_)\n",
    "    #if decision > 0.9:\n",
    "    #    df[\"cluster_id\"] = labels\n",
    "    #    return labels\n",
    "    #else:\n",
    "    #    hcluster.append(df[\"filename\"])\n",
    "    #    return hcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs more work later-- will require different method to define labels\n",
    "def group_Hcluster(df):\n",
    "    data = df[\"centers\"]\n",
    "    thresh = 14\n",
    "    hclusters = hcluster.fclusterdata(data, thresh, criterion=\"distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON file with all image labels\n",
    "labelpath = r\"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Labels/coco/20220227_dgc.json\"\n",
    "with open(labelpath) as f:\n",
    "  #df = pd.read_json(f)\n",
    "  cocozoo = pd.read_json(f) #delete this and use above instead once ready to run with all images\n",
    "\n",
    "#Directory of images-- remember to change this to the full directory when the script is ready\n",
    "imgpath = r\"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Data/Imagery/SB597/scratch/test\"\n",
    "imglist = os.listdir(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a multi-image subset to work with (delete this for full version)\n",
    "df = cocozoo[cocozoo[\"filename\"].isin(imglist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"c_x\"] = c_x\n",
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"c_y\"] = c_y\n",
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['x'] = x\n",
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['y'] = y\n",
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['w'] = w\n",
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_1849/3272824413.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['h'] = h\n"
     ]
    }
   ],
   "source": [
    "#CREATE NEW COLUMNS FOR INPUT INTO DBSCAN\n",
    "\n",
    "#Derive bounding box centers\n",
    "bboxes = df[\"bbox\"]\n",
    "c_x = []\n",
    "c_y = []\n",
    "x = []\n",
    "y = []\n",
    "w = []\n",
    "h = []\n",
    "centers = []\n",
    "for coord in bboxes:\n",
    "    center = (coord[0]+(coord[2]/2), coord[1]+(coord[3]/2))\n",
    "    c_x.append(center[0])\n",
    "    c_y.append(center[1])\n",
    "    x.append(coord[0])\n",
    "    y.append(coord[1])\n",
    "    w.append(coord[2])\n",
    "    h.append(coord[3])\n",
    "    centers.append(center)\n",
    "#Make these centers into a coordinate format\n",
    "coords = []\n",
    "for row in centers:\n",
    "    coord = list(row)\n",
    "    coords.append(coord)\n",
    "#Append new columns to dataframe for manipulating later\n",
    "df[\"c_x\"] = c_x\n",
    "df[\"c_y\"] = c_y\n",
    "df['x'] = x\n",
    "df['y'] = y\n",
    "df['w'] = w\n",
    "df['h'] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "      <th>image_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>labeler_id</th>\n",
       "      <th>c_x</th>\n",
       "      <th>c_y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>15014</td>\n",
       "      <td>[314.8125, 131, 91, 43]</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duck</td>\n",
       "      <td>2536</td>\n",
       "      <td>BDA_18a4_20181106_2_00295_01_04.png</td>\n",
       "      <td>437</td>\n",
       "      <td>360.3125</td>\n",
       "      <td>152.5</td>\n",
       "      <td>314.8125</td>\n",
       "      <td>131.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>15015</td>\n",
       "      <td>[266.8125, 7, 55, 59]</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duck</td>\n",
       "      <td>2536</td>\n",
       "      <td>BDA_18a4_20181106_2_00295_01_04.png</td>\n",
       "      <td>437</td>\n",
       "      <td>294.3125</td>\n",
       "      <td>36.5</td>\n",
       "      <td>266.8125</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15015</th>\n",
       "      <td>15016</td>\n",
       "      <td>[145.8125, 17, 62, 60]</td>\n",
       "      <td>3720.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duck</td>\n",
       "      <td>2536</td>\n",
       "      <td>BDA_18a4_20181106_2_00295_01_04.png</td>\n",
       "      <td>437</td>\n",
       "      <td>176.8125</td>\n",
       "      <td>47.0</td>\n",
       "      <td>145.8125</td>\n",
       "      <td>17.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>15017</td>\n",
       "      <td>[-18.1875, 15, 78, 38]</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duck</td>\n",
       "      <td>2536</td>\n",
       "      <td>BDA_18a4_20181106_2_00295_01_04.png</td>\n",
       "      <td>437</td>\n",
       "      <td>20.8125</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-18.1875</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15017</th>\n",
       "      <td>15018</td>\n",
       "      <td>[213.8125, 28, 54, 60]</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duck</td>\n",
       "      <td>2536</td>\n",
       "      <td>BDA_18a4_20181106_2_00295_01_04.png</td>\n",
       "      <td>437</td>\n",
       "      <td>240.8125</td>\n",
       "      <td>58.0</td>\n",
       "      <td>213.8125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation_id                     bbox    area  category_id category  \\\n",
       "15013          15014  [314.8125, 131, 91, 43]  3913.0            3     Duck   \n",
       "15014          15015    [266.8125, 7, 55, 59]  3245.0            3     Duck   \n",
       "15015          15016   [145.8125, 17, 62, 60]  3720.0            3     Duck   \n",
       "15016          15017   [-18.1875, 15, 78, 38]  2964.0            3     Duck   \n",
       "15017          15018   [213.8125, 28, 54, 60]  3240.0            3     Duck   \n",
       "\n",
       "       image_id                             filename  labeler_id       c_x  \\\n",
       "15013      2536  BDA_18a4_20181106_2_00295_01_04.png         437  360.3125   \n",
       "15014      2536  BDA_18a4_20181106_2_00295_01_04.png         437  294.3125   \n",
       "15015      2536  BDA_18a4_20181106_2_00295_01_04.png         437  176.8125   \n",
       "15016      2536  BDA_18a4_20181106_2_00295_01_04.png         437   20.8125   \n",
       "15017      2536  BDA_18a4_20181106_2_00295_01_04.png         437  240.8125   \n",
       "\n",
       "         c_y         x      y     w     h  \n",
       "15013  152.5  314.8125  131.0  91.0  43.0  \n",
       "15014   36.5  266.8125    7.0  55.0  59.0  \n",
       "15015   47.0  145.8125   17.0  62.0  60.0  \n",
       "15016   34.0  -18.1875   15.0  78.0  38.0  \n",
       "15017   58.0  213.8125   28.0  54.0  60.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['cluster_id'] = pd.Series()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename\n",
       "20211201_Atrisco_0465_07_01.png                 [0, 1, 2, 3, 4, 4, 3, 2, 0, 1, 0, 1, -1, 4, 3,...\n",
       "20220110_Bernardo_0001_01_03.png                [0, 1, 2, 3, -1, 4, 5, 6, 7, 1, 0, 2, 6, 7, 5,...\n",
       "20220110_Bernardo_0230_05_08.png                [0, -1, -1, 1, 2, 3, 4, 5, 6, 4, 2, 1, 3, 0, 7...\n",
       "20220110_Bernardo_0999_06_06.png                [0, 10, 1, 2, 3, -1, 4, 5, 12, 6, 7, 8, 9, 0, ...\n",
       "20220111_Bernardo_0491_03_07.png                [0, 1, 2, 0, 1, 2, 1, 2, 0, 1, 2, -1, 1, 2, 0,...\n",
       "20220111_LaJoya_1_0024_07_04.png                [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, ...\n",
       "20220111_LaJoya_1_0024_07_07.png                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 10, 7, 0...\n",
       "20220111_LaJoya_2_0196_06_03.png                [0, 1, 2, 5, 3, 4, 4, 3, 5, 1, 2, 0, 2, 1, 0, ...\n",
       "20220111_LaJoya_2_0196_07_05.png                                  [0, 0, 0, 0, -1, 0, 0, 0, 0, 0]\n",
       "BDA_12c_20181113_1_00425_01_07.png              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...\n",
       "BDA_12c_20181113_1_00473_01_03.png              [0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 2, -1, 2, 0,...\n",
       "BDA_12c_20181113_1_00473_02_04.png              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, -1, 12,...\n",
       "BDA_18a4_20181106_1_00244_05_02.png             [0, 1, 2, 3, 4, 5, 6, 4, 0, 5, 6, 2, 3, 1, 6, ...\n",
       "BDA_18a4_20181106_1_00244_06_01.png             [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...\n",
       "BDA_18a4_20181106_1_00244_07_01.png             [4, 0, 1, 2, 3, 4, 5, 6, 12, 7, 11, 0, -1, 3, ...\n",
       "BDA_18a4_20181106_2_00295_01_04.png             [0, 1, 2, 3, -1, 4, 9, 10, 5, 6, 7, 8, -1, 4, ...\n",
       "BDA_18a4_20181106_2_00557_03_06.png             [0, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 1, 3, 2, 0, ...\n",
       "BDA_18a4_20181106_2_00557_03_08.png                 [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
       "BDA_unknown_20181106_1_00041_02_08.png          [0, 1, 2, 3, -1, 1, 3, 0, 1, 2, 3, 0, 1, 2, 3,...\n",
       "BDA_unknown_20181106_1_00041_04_08.png          [0, 1, 2, 3, 4, 5, 6, 6, 5, 7, 0, 1, 2, 4, 3, ...\n",
       "BDA_unknown_20181106_1_00174_05_03.png          [5, 3, -1, -1, 0, -1, -1, 1, 0, 2, 3, 4, -1, 0...\n",
       "BDA_unknown_20181106_1_00174_05_07.png          [0, -1, 1, 2, 3, 5, 3, 2, 1, 0, 4, 5, 1, 4, 2,...\n",
       "FWS_MaxwellLake13_20171215_1_00613_02_03.png    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "FWS_MaxwellLake13_20171215_1_00613_03_03.png    [0, 1, 2, 3, 1, 0, 2, 3, 0, 1, 2, 3, 3, 2, 1, ...\n",
       "FWS_MaxwellLake13_20171215_3_01941_03_02.png        [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
       "FWS_MaxwellLake13_20171215_3_01942_06_08.png    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"filename\").apply(lambda x: group_DBSCAN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename\n",
       "20211201_Atrisco_0465_07_01.png                 [0, 1, 2, 3, 4, 4, 3, 2, 0, 1, 0, 1, -1, 4, 3,...\n",
       "20220110_Bernardo_0001_01_03.png                [0, 1, 2, 3, -1, 4, 5, 6, 7, 1, 0, 2, 6, 7, 5,...\n",
       "20220110_Bernardo_0230_05_08.png                [0, -1, -1, 1, 2, 3, 4, 5, 6, 4, 2, 1, 3, 0, 7...\n",
       "20220110_Bernardo_0999_06_06.png                [0, 10, 1, 2, 3, -1, 4, 5, 12, 6, 7, 8, 9, 0, ...\n",
       "20220111_Bernardo_0491_03_07.png                [0, 1, 2, 0, 1, 2, 1, 2, 0, 1, 2, -1, 1, 2, 0,...\n",
       "20220111_LaJoya_1_0024_07_04.png                [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, ...\n",
       "20220111_LaJoya_1_0024_07_07.png                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 10, 7, 0...\n",
       "20220111_LaJoya_2_0196_06_03.png                [0, 1, 2, 5, 3, 4, 4, 3, 5, 1, 2, 0, 2, 1, 0, ...\n",
       "20220111_LaJoya_2_0196_07_05.png                                  [0, 0, 0, 0, -1, 0, 0, 0, 0, 0]\n",
       "BDA_12c_20181113_1_00425_01_07.png              [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...\n",
       "BDA_12c_20181113_1_00473_01_03.png              [0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 2, -1, 2, 0,...\n",
       "BDA_12c_20181113_1_00473_02_04.png              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, -1, 12,...\n",
       "BDA_18a4_20181106_1_00244_05_02.png             [0, 1, 2, 3, 4, 5, 6, 4, 0, 5, 6, 2, 3, 1, 6, ...\n",
       "BDA_18a4_20181106_1_00244_06_01.png             [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...\n",
       "BDA_18a4_20181106_1_00244_07_01.png             [4, 0, 1, 2, 3, 4, 5, 6, 12, 7, 11, 0, -1, 3, ...\n",
       "BDA_18a4_20181106_2_00295_01_04.png             [0, 1, 2, 3, -1, 4, 9, 10, 5, 6, 7, 8, -1, 4, ...\n",
       "BDA_18a4_20181106_2_00557_03_06.png             [0, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 1, 3, 2, 0, ...\n",
       "BDA_18a4_20181106_2_00557_03_08.png                 [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
       "BDA_unknown_20181106_1_00041_02_08.png          [0, 1, 2, 3, -1, 1, 3, 0, 1, 2, 3, 0, 1, 2, 3,...\n",
       "BDA_unknown_20181106_1_00041_04_08.png          [0, 1, 2, 3, 4, 5, 6, 6, 5, 7, 0, 1, 2, 4, 3, ...\n",
       "BDA_unknown_20181106_1_00174_05_03.png          [5, 3, -1, -1, 0, -1, -1, 1, 0, 2, 3, 4, -1, 0...\n",
       "BDA_unknown_20181106_1_00174_05_07.png          [0, -1, 1, 2, 3, 5, 3, 2, 1, 0, 4, 5, 1, 4, 2,...\n",
       "FWS_MaxwellLake13_20171215_1_00613_02_03.png    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "FWS_MaxwellLake13_20171215_1_00613_03_03.png    [0, 1, 2, 3, 1, 0, 2, 3, 0, 1, 2, 3, 3, 2, 1, ...\n",
       "FWS_MaxwellLake13_20171215_3_01941_03_02.png        [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
       "FWS_MaxwellLake13_20171215_3_01942_06_08.png    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run DBSCAN\n",
    "filegroups = df.groupby(\"filename\")\n",
    "filegroups.apply(lambda x: group_DBSCAN(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cluster_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m categories \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mCrane\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mGoose\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mDuck\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#Derive median bounding box\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m refined \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mcluster_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg(pd\u001b[39m.\u001b[39mSeries\u001b[39m.\u001b[39mmedian)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m refined\u001b[39m.\u001b[39mreset_index(\u001b[39m\"\u001b[39m\u001b[39mcluster_id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/CV4Ecology/Prototyping/Scripts/Scratch/Refinement.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#Make median bounding box into its own column in list form\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/pandas/core/frame.py:7718\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7713\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7715\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7716\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7717\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7718\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   7719\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   7720\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   7721\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   7722\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   7723\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   7724\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   7725\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   7726\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7727\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   7728\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   7729\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    883\u001b[0m         obj,\n\u001b[1;32m    884\u001b[0m         keys,\n\u001b[1;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster_id'"
     ]
    }
   ],
   "source": [
    "#REFINEMENT STEP: DUCK, GOOSE, CRANE\n",
    "\n",
    "#Dictionary of category values\n",
    "categories = {1: \"Crane\", 2: 'Goose', 3:'Duck'}\n",
    "\n",
    "#Derive median bounding box\n",
    "refined = df.groupby(\"cluster_id\")['x','y','w','h'].agg(pd.Series.median)\n",
    "refined.reset_index(\"cluster_id\")\n",
    "#Make median bounding box into its own column in list form\n",
    "refined['bbox']= refined.values.tolist()\n",
    "#Derive plurality vote of class ID\n",
    "mode_class = df.groupby(\"cluster_id\")[\"filename\",'category_id'].agg(pd.Series.mode)\n",
    "#Join the refined results together\n",
    "refined_id = pd.merge(refined, mode_class, left_on=\"cluster_id\", right_on=\"cluster_id\")\n",
    "#Add back a column with category name to the refined results (optional)\n",
    "refined_id['category'] = refined_id[\"category_id\"].map(categories)\n",
    "refined_id = refined_id.drop(columns=['x','y','w','h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REFINEMENT STEP: DGC, SEAGULL\n",
    "\n",
    "#Dictionary of category values\n",
    "categories = {1: \"Crane\", 2: 'Goose', 3:'Duck', 4:'Seagull'}\n",
    "\n",
    "#Derive median bounding box \n",
    "refined = filegroups.groupby(\"cluster_id\")['x','y','w','h'].agg(pd.Series.median)\n",
    "refined.reset_index(\"cluster_id\")\n",
    "#Make median bounding box into its own column in list form\n",
    "refined['bbox']= refined.values.tolist()\n",
    "#Derive plurality vote of class ID\n",
    "mode_class = filegroups.groupby(\"cluster_id\")[\"filename\",'category_id'].agg(pd.Series.mode)\n",
    "#Join the refined results together\n",
    "refined_id = pd.merge(refined, mode_class, left_on=\"cluster_id\", right_on=\"cluster_id\")\n",
    "#Add back a column with category name to the refined results (optional)\n",
    "refined_id['category'] = refined_id[\"category_id\"].map(categories)\n",
    "refined_id = refined_id.drop(columns=['x','y','w','h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT OF REFINED RESULTS FOR USE AS TRAIN/VAL/TEST (not split yet; determine split after getting new data stats)\n",
    "\n",
    "#add individual annotation ID column\n",
    "export = refined_id.reset_index\n",
    "#drop \"cluster ID\" column\n",
    "export.drop(columns=\"cluster_id\")\n",
    "#save to csv\n",
    "exportconsensus = datetime.now().strftime('%Y%m%d_consensuslabels.csv')\n",
    "export.to_csv(exportconsensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT OF ANALYSIS DATAFRAME\n",
    "df_analysis = pd.merge(df, refined_id, left_on=\"cluster_id\", right_on=\"cluster_id\")\n",
    "df_analysis = df_analysis.drop(columns=['centers','area','x','y','w','h', 'filename_y'])\n",
    "df_analysis = df_analysis.rename(columns={'filename_x':'filename', 'bbox_x': 'bbox_orig', 'category_id_x': 'cat_id_orig', \"category_x\": \"cat_orig\", 'bbox_y': 'bbox_refined', 'category_id_y': 'cat_id_refined', \"category_y\": \"cat_refined\"})\n",
    "exportanalysis = datetime.now().strftime('%Y%m%d_analysislabels.csv')\n",
    "df_analysis.to_csv(exportanalysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
